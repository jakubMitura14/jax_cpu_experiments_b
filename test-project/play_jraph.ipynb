{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "import jax.random as random\n",
    "import einops\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def get_example_image(image_shape, sv_r, indexes_of_high, mean_0,var_0,mean_1,var_1,rng_key):\n",
    "    \"\"\"\n",
    "    we will create a simulation of the image with supervoxel segmentation each super voxel \n",
    "    at first extremely simplified case with square supervoxels each filled with predefined gausiians output\n",
    "    we will generate couple of such and try to make a graph model that would recognize the diffrences\n",
    "    indexes_of_high - will be a set of tuples indicating w and  h coordinates\n",
    "    \"\"\" \n",
    "    #1)create empy image\n",
    "    image= jnp.zeros(image_shape)\n",
    "    #2) reshape to get as last two dims sv size\n",
    "    image= einops.rearrange(image, '(w sw) (h sh) ->w h sw sh', sw=sv_r,sh=sv_r )\n",
    "    image=numpyro.sample('mu', dist.Normal(mean_0,var_0), sample_shape=image.shape,rng_key=rng_key)\n",
    "    #populate the sv areas with goussian noise of mean and var 1 if index is in indexes_of_high and mean and var 0 otherwise\n",
    "    rng_key_new, old= random.split(rng_key)\n",
    "    for coord in indexes_of_high:\n",
    "        rng_key_new, old= random.split(rng_key_new)\n",
    "        x,y=coord\n",
    "        image.at[x,y,:,:].set(numpyro.sample('mu_1', dist.Normal(mean_1,var_1), sample_shape=(sv_r,sv_r),rng_key=rng_key_new))\n",
    "\n",
    "    #reshape back to original image shape\n",
    "    image= einops.rearrange(image, 'w h sw sh -> (w sw) (h sh) ', sw=sv_r,sh=sv_r )\n",
    "    return image\n",
    "\n",
    "rng_key = random.PRNGKey(3)\n",
    "rng_key_new,old = random.split(rng_key)\n",
    "\n",
    "mean_0 =1\n",
    "var_0=1\n",
    "mean_1=2\n",
    "var_1=0.5\n",
    "image_shape=(64,64)\n",
    "sv_r=8\n",
    "indexes_of_high=[(0,0), (1,1), (2,2)]\n",
    "get_example_image(image_shape, sv_r, indexes_of_high, mean_0,var_0,mean_1,var_1,old)\n",
    "v_get_example_image=jax.vmap(get_example_image,in_axes=(None,None,None,None,None,None,None,0))\n",
    "\n",
    "#                             ,in_axes=(0, 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_example_dataset():\n",
    "    \"\"\" \n",
    "    using get_example_image  we will create multiple instances of diffrent images - we will save images\n",
    "    task here will be graph level predictions \n",
    "    \"\"\"\n",
    "    num_per_class=50\n",
    "    mean_0 =1\n",
    "    var_0=1\n",
    "    mean_1=2\n",
    "    var_1=0.5\n",
    "    image_shape=(64,64)\n",
    "    sv_r=8\n",
    "    a=v_get_example_image(image_shape, sv_r, [(0,0), (1,1), (2,2), (3,3)], mean_0,var_0,mean_1,var_1,random.split(rng_key_new,num_per_class  ))\n",
    "    b=v_get_example_image(image_shape, sv_r, [(0,0), (0,1), (0,2), (0,3)], mean_0,var_0,mean_1,var_1,random.split(rng_key_new,num_per_class  ))\n",
    "    c=v_get_example_image(image_shape, sv_r, [(0,0), (1,1), (0,1), (1,1)], mean_0,var_0,mean_1,var_1,random.split(rng_key_new,num_per_class  ))\n",
    "    images=jnp.concatenate([a,b,c],axis=0)\n",
    "    labels_a= jnp.ones(num_per_class)\n",
    "    labels_b= jnp.ones(num_per_class)*2\n",
    "    labels_c= jnp.ones(num_per_class)*3\n",
    "    labels= jnp.concatenate([labels_a,labels_b, labels_c])\n",
    "    return images,labels\n",
    "\n",
    "dummy_dataset=build_example_dataset()\n",
    "dummy_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_graph_from_image_differentaible():\n",
    "#     \"\"\" \n",
    "#     we will create a graph from a given image a procedure need to be differentiable\n",
    "#     \"\"\"\n",
    "#     # first we need to encode the svs into tokens - we will flatten and apply dense\n",
    "    \n",
    "#     #  now a bit harder we need to get the edges for now we will just connect with previous/next in each axis\n",
    "#     node_features = jnp.array([[0.], [2.], [4.], [6.]])\n",
    "#       senders = jnp.array([0, 1, 2, 3, 0])\n",
    "#   receivers = jnp.array([1, 2, 0, 0, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jraph\n",
    "# import jax.numpy as jnp\n",
    "\n",
    "# # Define a three node graph, each node has an integer as its feature.\n",
    "# node_features = jnp.array([[0.], [1.], [2.]])\n",
    "\n",
    "# # We will construct a graph for which there is a directed edge between each node\n",
    "# # and its successor. We define this with `senders` (source nodes) and `receivers`\n",
    "# # (destination nodes).\n",
    "# senders = jnp.array([0, 1, 2])\n",
    "# receivers = jnp.array([1, 2, 0])\n",
    "\n",
    "# # You can optionally add edge attributes.\n",
    "# edges = jnp.array([[5.], [6.], [7.]])\n",
    "\n",
    "# # We then save the number of nodes and the number of edges.\n",
    "# # This information is used to make running GNNs over multiple graphs\n",
    "# # in a GraphsTuple possible.\n",
    "# n_node = jnp.array([3])\n",
    "# n_edge = jnp.array([3])\n",
    "\n",
    "# # Optionally you can add `global` information, such as a graph label.\n",
    "\n",
    "# global_context = jnp.array([[1]])\n",
    "# graph = jraph.GraphsTuple(nodes=node_features, senders=senders, receivers=receivers,\n",
    "# edges=edges, n_node=n_node, n_edge=n_edge, globals=global_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 18\n",
    "f = h5py.File('/workspaces/jax_cpu_experiments_b/hdf5_loc/example_mask.hdf5', 'r+')\n",
    "label=f[\"label\"][:,:]\n",
    "image=f[\"image\"][:,:]\n",
    "masks=f[\"masks\"][:,:,:]\n",
    "plt.imshow(image, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies =np.arange(81).reshape(9,9)\n",
    "indicies_a=indicies[0::2,0::2]\n",
    "indicies_b=indicies[1::2,0::2]\n",
    "indicies_c=indicies[0::2,1::2]\n",
    "indicies_d=indicies[1::2,1::2]\n",
    "def get_arange_the_same_shape(arr):\n",
    "    sh=arr.shape\n",
    "    to_add=sh[0]*sh[1]\n",
    "    return np.arange(to_add).reshape(sh),to_add\n",
    "\n",
    "indicies_a,to_add_a=get_arange_the_same_shape(indicies_a)\n",
    "indicies_b,to_add_b=get_arange_the_same_shape(indicies_b)\n",
    "indicies_c,to_add_c=get_arange_the_same_shape(indicies_c)\n",
    "indicies_d,to_add_d=get_arange_the_same_shape(indicies_d)\n",
    "\n",
    "indicies_b=indicies_b+to_add_a\n",
    "indicies_c=indicies_c+to_add_a+to_add_b\n",
    "indicies_d=indicies_d+to_add_a+to_add_b+to_add_c\n",
    "\n",
    "indicies[0::2,0::2]=indicies_a\n",
    "indicies[1::2,0::2]=indicies_b\n",
    "indicies[0::2,1::2]=indicies_c\n",
    "indicies[1::2,1::2]=indicies_d\n",
    "\n",
    "\n",
    "indicies_a=jnp.pad(indicies_a,((1,1),(1,1)), 'constant', constant_values=((-1,-1),(-1,-1)))\n",
    "indicies_b=jnp.pad(indicies_b,((1,1),(1,1)), 'constant', constant_values=((-1,-1),(-1,-1)))\n",
    "indicies_c=jnp.pad(indicies_c,((1,1),(1,1)), 'constant', constant_values=((-1,-1),(-1,-1)))\n",
    "indicies_d=jnp.pad(indicies_d,((1,1),(1,1)), 'constant', constant_values=((-1,-1),(-1,-1)))\n",
    "\n",
    "print(f\"indicies_a {indicies_a.shape} indicies_b {indicies_b.shape} indicies_c {indicies_c.shape} indicies_d {indicies_d.shape} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbour_indicies(curr_x,curr_y,curr_analyzed,x_op,y_op,x_subtr,y_subtr,x_add,y_add):\n",
    "    left=y_op[curr_x,curr_y-y_subtr]\n",
    "    right=y_op[curr_x,curr_y+y_add]\n",
    "    bottom=x_op[curr_x+x_add,curr_y]\n",
    "    top=x_op[curr_x-x_subtr,curr_y]\n",
    "    curr=curr_analyzed[curr_x,curr_y]\n",
    "    return jnp.array([[curr,left],[curr,right],[curr,bottom],[curr,top]])\n",
    "\n",
    "def get_neighbours_a(point,indicies_a,indicies_b,indicies_c,indicies_d):\n",
    "    curr_x,curr_y=point\n",
    "    x_subtr=1\n",
    "    y_subtr=1\n",
    "    x_add=0\n",
    "    y_add=0\n",
    "    curr_analyzed=indicies_a\n",
    "    x_op=indicies_b\n",
    "    y_op=indicies_c\n",
    "    return get_neighbour_indicies(curr_x,curr_y,curr_analyzed,x_op,y_op,x_subtr,y_subtr,x_add,y_add)\n",
    "\n",
    "\n",
    "def get_neighbours_b(point,indicies_a,indicies_b,indicies_c,indicies_d):\n",
    "    curr_x,curr_y=point\n",
    "    x_subtr=0\n",
    "    y_subtr=1\n",
    "    x_add=1\n",
    "    y_add=0\n",
    "    curr_analyzed=indicies_b\n",
    "    x_op=indicies_a\n",
    "    y_op=indicies_d\n",
    "    return get_neighbour_indicies(curr_x,curr_y,curr_analyzed,x_op,y_op,x_subtr,y_subtr,x_add,y_add)\n",
    "\n",
    "def get_neighbours_c(point,indicies_a,indicies_b,indicies_c,indicies_d):\n",
    "    curr_x,curr_y=point\n",
    "    x_subtr=1\n",
    "    y_subtr=0\n",
    "    x_add=0\n",
    "    y_add=1\n",
    "    curr_analyzed=indicies_c\n",
    "    x_op=indicies_d\n",
    "    y_op=indicies_a\n",
    "    return get_neighbour_indicies(curr_x,curr_y,curr_analyzed,x_op,y_op,x_subtr,y_subtr,x_add,y_add)\n",
    "\n",
    "def get_neighbours_d(point,indicies_a,indicies_b,indicies_c,indicies_d):\n",
    "    curr_x,curr_y=point\n",
    "    x_subtr=0\n",
    "    y_subtr=0\n",
    "    x_add=1\n",
    "    y_add=1\n",
    "    curr_analyzed=indicies_d\n",
    "    x_op=indicies_c\n",
    "    y_op=indicies_b\n",
    "    return get_neighbour_indicies(curr_x,curr_y,curr_analyzed,x_op,y_op,x_subtr,y_subtr,x_add,y_add)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dilateted_shape=(9,9)\n",
    "points_grid=jnp.mgrid[0:dilateted_shape[0], 0:dilateted_shape[1]]+1\n",
    "points_grid=einops.rearrange(points_grid,'p x y-> (x y) p')\n",
    "\n",
    "v_get_neighbours_a=jax.vmap(get_neighbours_a, in_axes=(0,None,None,None,None))\n",
    "v_get_neighbours_b=jax.vmap(get_neighbours_b, in_axes=(0,None,None,None,None))\n",
    "v_get_neighbours_c=jax.vmap(get_neighbours_c, in_axes=(0,None,None,None,None))\n",
    "v_get_neighbours_d=jax.vmap(get_neighbours_d, in_axes=(0,None,None,None,None))\n",
    "\n",
    "def get_all_neighbours(v_get_neighbours,points_grid,indicies_a,indicies_b,indicies_c,indicies_d):\n",
    "#get_neighbours_a(point,indicies_a,indicies_b,indicies_c,indicies_d)\n",
    "    neighbours=v_get_neighbours(points_grid,indicies_a,indicies_b,indicies_c,indicies_d)\n",
    "    neighbours= einops.rearrange(neighbours,'a b p->(a b) p')\n",
    "    correct_neighbours=(neighbours==-1)\n",
    "    correct_neighbours=jnp.logical_not(jnp.any(correct_neighbours,axis=1))\n",
    "    return neighbours[correct_neighbours]\n",
    "\n",
    "all_a=get_all_neighbours(v_get_neighbours_a,points_grid,indicies_a,indicies_b,indicies_c,indicies_d)\n",
    "all_b=get_all_neighbours(v_get_neighbours_b,points_grid,indicies_a,indicies_b,indicies_c,indicies_d)\n",
    "all_c=get_all_neighbours(v_get_neighbours_c,points_grid,indicies_a,indicies_b,indicies_c,indicies_d)\n",
    "all_d=get_all_neighbours(v_get_neighbours_d,points_grid,indicies_a,indicies_b,indicies_c,indicies_d)\n",
    "\n",
    "all_neighbours=jnp.concatenate([all_a,all_b,all_c,all_d])\n",
    "all_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neighbours[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_image =np.ones((9,9))\n",
    "dummy_image[2,2]=3\n",
    "dummy_image[1,2]=4\n",
    "dummy_image[2,1]=5\n",
    "dummy_image[2,3]=6\n",
    "dummy_image[3,2]=7\n",
    "dummy_image_a=dummy_image[0::2,0::2]\n",
    "dummy_image_b=dummy_image[1::2,0::2]\n",
    "dummy_image_c=dummy_image[0::2,1::2]\n",
    "dummy_image_d=dummy_image[1::2,1::2]\n",
    "\n",
    "# dummy_image_a= einops.rearrange(dummy_image_a,'a b-> (a b)')\n",
    "dummy_image_cat= np.concatenate([dummy_image_a.flatten(),dummy_image_b.flatten(),dummy_image_c.flatten(),dummy_image_d.flatten()])\n",
    "dummy_image_cat= np.stack([np.arange(dummy_image_cat.shape[0]),dummy_image_cat],axis=1 )\n",
    "list(filter(lambda row: row[1]>1,dummy_image_cat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda row: row[0]==6,all_neighbours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "so we need for each initial masks get mask of the same x and y shape but set it as\n",
    "aranged so we will get mask unique indicies\n",
    "then to each mask we will add sums to get completely unique indicies \n",
    "so to indicies a 0 to b x*y (shape) to c x*y*2 and to d x*y*3\n",
    "this should give us the correct indicies that will be valid after flattening the tokens\n",
    "now we have neighbour svs of each entry of the each mask in some other mask by construction\n",
    "in order to deal easier with corner cases we can pad the arranged array with lets say -1 and then filter out sch cases\n",
    "important consideration also is that initial grid will be divided into masks and it cen get uneven shapes - we need to adress it \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
